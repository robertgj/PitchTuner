<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.7"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>PitchTuner: PitchTuner : Implementation of a YIN pitch estimator and GUI for Linux</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">PitchTuner
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.7 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',false,false,'search.php','Search');
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title"><a class="el" href="classPitchTuner.html">PitchTuner</a> : Implementation of a YIN pitch estimator and GUI for Linux </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="intro_sec"></a>
Introduction</h1>
<p>This project implements a GUI for the <em>YIN</em> [1] pitch estimator.</p>
<p>More recent implementations of pitch estimators are available on the web:</p>
<p><em>pYIN</em> [2] adds a probabilistic hidden-Markov model to make multiple YIN pitch estimates then performs Viterbi decoding of the pitch trajectory to find a final precise estimate. Software is <a href="http://code.soundsoftware.ac.uk/projects/pyin">available</a>.</p>
<p><em>CREPE</em> [3] is "based on a deep convolutional neural network that operates
directly on the time-domain waveform". Software is <a href="https://github.com/marl/crepe">available</a>.</p>
<p><em>Melodia</em> [4] is a "system for the automatic extraction of the main melody from 
polyphonic music recordings".</p>
<p><a href="https://essentia.upf.edu">essentia</a> is "... a C++ library for
audio and music analysis, description and synthesis". It includes implementations of pYIN, CREPE and Melodia.</p>
<h2><a class="anchor" id="References"></a>
References</h2>
<p>[1] "YIN, A fundamental frequency estimator for speech and music", A. de Cheveigne and H. Kawahara, Journal of the Acoustical Society of America, Vol. 11, No. 4, April 2002, pp. 1917-1930.</p>
<p>[2] "PYIN: A FUNDAMENTAL FREQUENCY ESTIMATOR USING PROBABILISTIC THRESHOLD 
DISTRIBUTIONS", M. Mauch and S. Dixon, ICASSP 2014, pp. 650-663.</p>
<p>[3] "CREPE: A CONVOLUTIONAL REPRESENTATION FOR PITCH ESTIMATION" J. W. Kim, J. Salamon, P Li and J. P. Bello, ICASSP 2018, pp. 161-165.</p>
<p>[4] "Melody Extraction From Polyphonic Music Signals Using Pitch Contour 
Characteristics", J. Salamon and E. GÃ³mez, IEEE Transactions on Audio, Speech, and Language Processing, Vol. 20, No. 6, August 2012, pp. 1759-1770.</p>
<h1><a class="anchor" id="algorithm_sec"></a>
The YIN algorithm</h1>
<h2><a class="anchor" id="autocorrelation_sec"></a>
Step 1 : Autocorrelation</h2>
<p>Use the autocorrelation method. For integration window, <code>W</code> : </p><p class="formulaDsp">
\[ r_{t}(\tau)=\sum_{j=t+1}^{t+W}x_{j}x_{j+\tau} \]
</p>
<h2><a class="anchor" id="difference_sec"></a>
Step 2 : Difference function</h2>
<p>Model as periodic: </p><p class="formulaDsp">
\[ x_{t}-x_{t+T}=0 \]
</p>
<p> so: </p><p class="formulaDsp">
\[ \sum_{j=t+1}^{t+W}(x_{j}-x_{j+T})^{2}=0 \]
</p>
<p> For unknown period, \(T\), define: </p><p class="formulaDsp">
\[ d_{t}(T)=\sum_{j=t+1}^{t+W}(x_{j}-x_{j+T})^{2} \]
</p>
<p> and search for values of T at which \(d_{t}=0\). Expand \(d_{t}(T)\) in terms of \(r_{t}\): </p><p class="formulaDsp">
\[ d_{t}(T)=r_{t}(0)+r_{t+T}(0)-2r_{t}(T)\]
</p>
<p> For \(d_{t}(T)\) the sample time lies in \(t-\frac{T}{2}-\frac{W}{2}+1\) to \(t+\frac{T}{2}+\frac{W}{2}\). For convenience \(T&lt;2W\) and the sample time lies in \(t-\frac{3W}{2}+1\) to \(t-\frac{3W}{2}\).</p>
<h2><a class="anchor" id="cum_mean_sec"></a>
Step 3 : Cumulative mean normalised difference</h2>
<p class="formulaDsp">
\[ d&#39;_{t}(T)=\left\{ \begin{array}{cc}
         1 &amp; \text{if } T=0 \\
         d_{t}(T)/\left[\frac{1}{T}\sum_{j=1}^{T}d_{t}(j)\right] &amp;
         \text{ otherwise}
      \end{array}\right.\]
</p>
<p> Benefits:</p><ul>
<li>reduces `&lsquo;too high&rsquo;' errors</li>
<li>don't need upper frequency limit on search to avoid zero-lag dip</li>
<li>normalises for next step</li>
</ul>
<h2><a class="anchor" id="abs_thresh_sec"></a>
Step 4 : Absolute threshold</h2>
<p>Set threshold. Choose the smallest \(\tau\) giving minimum of \(d_{t}&#39;(T)\) deeper than that threshold.</p>
<h2><a class="anchor" id="para_interp_sec"></a>
Step 5 : Parabolic interpolation</h2>
<p>Increase accuracy by parabolic interpolation near each minimum of \(d_{t}(T)\) and \(d_{t}&#39;(T)\). </p>
<h2><a class="anchor" id="local_est_sec"></a>
Step 6 : Best local estimate</h2>
<p>From [1, Section II.F]:</p>
<blockquote class="doxtable">
<p>&zwj;For each time index \(t\), search for a minimum of \(d_{\theta}&#39;(T_{\theta})\) for \(\theta\) within a small interval \(\left[t-T_{max}/2,\,t+T_{max}/2\right]\), where \(T_{\theta}\) is the estimate at time \(\theta\) and \(T_{max}\) is the largest expected period. Based on this initial estimate, the estimation algorithm is applied again with a restricted search range to obtain the final estimate. </p>
</blockquote>
<p>I do not understand why this repeated search should produce an improved pitch estimate.</p>
<h2><a class="anchor" id="enhancement_sec"></a>
Enhancements</h2>
<h3><a class="anchor" id="varying_dc_sec"></a>
Remove slowly varying DC</h3>
<p>See Section VI.C of the reference. A slowly varing DC offset is produced when the speakers mouth is too close to the microphone. The effect of a DC ramp can be removed by setting the derivative of \(d_{t}(T)\) with respect to the DC offset to zero. To remove a ramp with slope \(\Delta\) added to the input, \(x_{j}\):  </p><p class="formulaDsp">
\[
 \begin{eqnarray*}
      d_{t}(T)  &amp;= &amp; \sum_{j=t+1}^{t+W}(x_{j}-(x_{j+T}-T\Delta))^{2} \\
                &amp;= &amp; \sum_{j=t+1}^{t+W}(x_{j}-x_{j+T})^{2}+WT^{2}\Delta^{2}
         +2T\triangle\sum_{j=t+1}^{t+W}(x_{j}-x_{j+T}) \\
  \frac{d}{d\triangle} d_{t}(T) &amp;= &amp; 
   2WT^{2}\Delta+2T\sum_{j=t+1}^{t+W}(x_{j}-x_{j+T})
 \end{eqnarray*}
 \]
</p>
<p> So insert: </p><p class="formulaDsp">
\[ \Delta  = -\frac{1}{TW}\sum_{j=t+1}^{t+W}(x_{j}-x_{j+T})\]
</p>
<p> and:  </p><p class="formulaDsp">
\[  \begin{eqnarray*}
    d_{t}(T) &amp; = &amp; \sum_{j=t+1}^{t+W}(x_{j}-x_{j+T})^{2}
               -\frac{1}{W}\left[\sum_{j=t+1}^{t+W}(x_{j}-x_{j+T})\right]^{2} \\
             &amp; = &amp; r_{t}(0)+r_{t+T}(0)-2r_{t}(T)
                 -\frac{1}{W}\left[\sum_{j=t+1}^{t+W}(x_{j}-x_{j+T})\right]^{2}
 \end{eqnarray*}
 \]
</p>
<h1><a class="anchor" id="implement_sec"></a>
Implementation</h1>
<p>I assume a Linux operating system and the ALSA sound system. The programming language is C++ and I use the wxWidgets GUI toolkit. The YIN pitch estimation algorithm runs in a thread. The wxWidgets GUI has the following events:</p><ul>
<li><code>ID_Pitch</code> : indicates that a pitch estimate is available</li>
<li><code>ID_ThreadError</code> : an error occurred in the pitch estimation thread</li>
<li><code>ID_EOS</code> : end-of-stream, an error if using an audio device</li>
<li><code>ID_DeviceOptions</code> : a request to display the device options dialog box</li>
<li><code>ID_About</code> : a request to display the "about" message box</li>
<li><code>ID_Quit</code> : a request to exit</li>
<li><code>ID_GuiTest</code> : a request to update the fake pitch estimate in the GUI after the GUI test timer times out</li>
</ul>
<h2><a class="anchor" id="alsa_sec"></a>
ALSA and wav file interface</h2>
<p>The ALSA specific source files are in the </p><div class="fragment"><div class="line">src/<a class="code hl_namespace" href="namespaceSimpleAudio.html">SimpleAudio</a>/alsa </div>
<div class="ttc" id="anamespaceSimpleAudio_html"><div class="ttname"><a href="namespaceSimpleAudio.html">SimpleAudio</a></div><div class="ttdef"><b>Definition</b> <a href="saCircBuff_8h_source.html#l00018">saCircBuff.h:19</a></div></div>
</div><!-- fragment --><p> directory. The Linux ALSA sound system is implemented as a layer on top of PipeWire or PulseAudio or ... and the API refers to device names that are internally mapped to UNIX device files. In this project, the audio input is referred to as <code>"default"</code> and it is up to the user to configure the audio mixer with an application like <em>pavucontrol</em> or <em>alsamixer</em>.</p>
<p>The available ALSA input and output device names are listed by </p><div class="fragment"><div class="line">arecord -L </div>
</div><!-- fragment --><p> and </p><div class="fragment"><div class="line">aplay -L </div>
</div><!-- fragment --><p>The <code><a class="el" href="namespaceSimpleAudio.html">SimpleAudio</a></code> library provides an interface to input signals from the default ALSA capture device or from <code>wav</code> or text files. Output to <code>wav</code> files is supported. The ALSA specific source files are in the <code>src/<code>SimpleAudio/<code>alsa</code> directory</code>.</code> </p>
<h3><a class="anchor" id="loopback_sec"></a>
ALSA snd_aloop device</h3>
<p>A loop-back sound device is useful for testing. The pitch estimator was originally implemented on FreeBSD/OSS and Windows Mobile. For OSS, sound devices appear under <code>/dev</code>, as is usual for UNIX, and I implemented a <code>snd_echo</code> loop-back device. The ALSA loop-back device driver is loaded at run-time with </p><div class="fragment"><div class="line">modprobe snd_aloop </div>
</div><!-- fragment --><p> and at boot-time with (note the spelling): </p><div class="fragment"><div class="line">$ cat /etc/modules-load.d/snd-aloop.conf</div>
<div class="line">snd_aloop</div>
</div><!-- fragment --><p> Here is an example of copying 4 seconds of a file through the loop-back device: </p><div class="fragment"><div class="line">(arecord -D hw:Loopback,1 -f S16_LE -r 48000 -d 4 out.wav &amp;); \</div>
<div class="line">(aplay -D hw:Loopback,0 in.wav);</div>
</div><!-- fragment --><p> Unfortunately, I find that:</p><ul>
<li>loading the <code>snd_aloop</code> module disables access to my hardware sound card</li>
<li>using the <code>snd_aloop</code> module triggers selinux warnings</li>
<li>once loaded, it is difficult to unload the <code>snd_aloop</code> module</li>
</ul>
<h2><a class="anchor" id="sasample_sec"></a>
saSample</h2>
<p>This project attempts to handle three sample types:</p><ul>
<li>the source sample,<code>saSourceType</code> </li>
<li>the internal sample used for computations, <code>saSample</code> </li>
<li>the sink sample, <code>saSinkType</code> </li>
</ul>
<p>The ALSA device input and output types are "hard-wired" to <code>int16_t</code> in the files <code><a class="el" href="saDeviceType_8h.html" title="Device data format.">saDeviceType.h</a></code>, <code><a class="el" href="saInputSource_8h.html" title="Abstract base class for a simple audio input.">saInputSource.h</a></code> and <code><a class="el" href="saOutputSink_8h.html" title="Abstract base class for a simple audio output.">saOutputSink.h</a></code>, respectively. The file <code><a class="el" href="saSample_8h.html" title="Public interface for a floating point audio sample.">saSample.h</a></code> defines the <code>saSample</code> internal type as a <code>float</code> and defines arithmetic operations on the <code>saSample</code> data with compile time options for saturation on over-flow, under-flow exceptions and over-flow exceptions. Similarly, the file <code><a class="el" href="saSampleTest_8h.html" title="Public interface for testing a fixed point audio sample.">saSampleTest.h</a></code> defines the <code>saSampleTest</code> internal type as a <code>int32_t</code>. In both cases, the base type template is defined in <code><a class="el" href="saSampleBase_8h.html" title="Public interface for a simple fixed point or integer audio sample.">saSampleBase.h</a></code>.</p>
<h2><a class="anchor" id="preprocessor_sec"></a>
Pre-Processing</h2>
<p>The file <code><a class="el" href="PreProcessor_8cc.html">PreProcessor.cc</a></code> implements preprocessing of the input audio stream:</p><ul>
<li>low-pass filter and decimate the input signal</li>
<li>high-pass filter to remove DC component</li>
<li>apply AGC</li>
</ul>
<p><code><a class="el" href="ButterworthFilter_8h.html" title="Implemetation of Butterworth filters as a cascade of second-order state-space sections.">ButterworthFilter.h</a></code> implements fourth-order low-pass and second-order high-pass Butterworth filters. <code><a class="el" href="AutomaticGainControl_8h.html" title="Automatic gain control functor.">AutomaticGainControl.h</a></code> implements a simple automatic gain control.</p>
<h2><a class="anchor" id="pitchest_sec"></a>
Pitch estimation</h2>
<p><code><a class="el" href="PitchTracker_8cc.html" title="A C++ implementation of the YIN pitch estimation algorithm See PitchTuner.h for a description of the ...">PitchTracker.cc</a></code> implements the YIN pitch estimator algorithm.</p>
<h2><a class="anchor" id="testing_sec"></a>
Testing</h2>
<p>The shell scripts in the <code>test</code> directory test the command line programs that exercise the preprocessing and pitch estimation routines. Run them under <a href="https://www.valgrind.org/">valgrind</a> with: </p><div class="fragment"><div class="line">$ export VALGRIND_CMD=<span class="stringliteral">&quot;valgrind -q --leak-check=full&quot;</span></div>
<div class="line">$ <span class="keywordflow">for</span> file in `ls -1 test/00/t00??a.sh` ; <span class="keywordflow">do</span> sh $file ; done</div>
</div><!-- fragment --><h2><a class="anchor" id="gui_sec"></a>
GUI</h2>
<p><code><a class="el" href="PitchTuner_8cc.html" title="wxWidgets application for the PitchTracker pitch estimator">PitchTuner.cc</a></code> implements a <a href="https://www.wxwidgets.org/">wxWidgets</a> GUI that displays the pitch estimate on a meter. The musical notes displayed are the 12-tone equal-tempered scale (12-TET). The <em>Options</em> are displayed by the keyboard combination <em>Alt+O</em>. For example, <em>Alt+O</em> followed by <em>Q</em> exits the program.</p>
<p>The <code><a class="el" href="classPitchTuner.html">PitchTuner</a></code> command-line options are: </p><div class="fragment"><div class="line">$ bin/<a class="code hl_class" href="classPitchTuner.html">PitchTuner</a> --help</div>
<div class="line"><a class="code hl_function" href="AutomaticGainControl__test_8cc.html#ae28fba57a1edfa47dfb0ed05fb38131c">Usage</a>: <a class="code hl_class" href="classPitchTuner.html">PitchTuner</a> [-?] [--file &lt;str&gt;] [--device &lt;str&gt;] [--sample_rate &lt;num&gt;]</div>
<div class="line">[--channel &lt;num&gt;] [--latency_ms &lt;num&gt;] [--subsample &lt;num&gt;] [--lpcutoff &lt;num&gt;]</div>
<div class="line">[--hpcutoff &lt;num&gt;] [--disable_hp_filter] [--disable_agc] [--window_ms &lt;num&gt;]</div>
<div class="line">[--lags_ms &lt;num&gt;] [--sample_ms &lt;num&gt;] [--threshold &lt;double&gt;] [--removeDC]</div>
<div class="line">[--A4Frequency &lt;num&gt;] [--gui_test] [--debug]</div>
<div class="line">  -?, --help            show help message</div>
<div class="line">  --file=&lt;str&gt;          input file</div>
<div class="line">  --device=&lt;str&gt;        input device</div>
<div class="line">  --sample_rate=&lt;num&gt;   sample rate</div>
<div class="line">  --channel=&lt;num&gt;       input device channel</div>
<div class="line">  --latency_ms=&lt;num&gt;    device storage latency (ms)</div>
<div class="line">  --subsample=&lt;num&gt;     waveform subsample ratio</div>
<div class="line">  --lpcutoff=&lt;num&gt;      lowpass cutoff frequency</div>
<div class="line">  --hpcutoff=&lt;num&gt;      highpass cutoff frequency</div>
<div class="line">  --disable_hp_filter   disable highpass filter</div>
<div class="line">  --disable_agc         disable AGC</div>
<div class="line">  --window_ms=&lt;num&gt;     correlation window width (ms)</div>
<div class="line">  --lags_ms=&lt;num&gt;       maximum correlation lags (ms)</div>
<div class="line">  --sample_ms=&lt;num&gt;     pitch estimate interval (ms)</div>
<div class="line">  --threshold=&lt;<span class="keywordtype">double</span>&gt;  difference function maximum</div>
<div class="line">  --removeDC            enable DC removal</div>
<div class="line">  --A4Frequency=&lt;num&gt;   nominal A4 frequency</div>
<div class="line">  --gui_test            enable GUI testing</div>
<div class="line">  --debug               enable debugging information</div>
<div class="ttc" id="aAutomaticGainControl__test_8cc_html_ae28fba57a1edfa47dfb0ed05fb38131c"><div class="ttname"><a href="AutomaticGainControl__test_8cc.html#ae28fba57a1edfa47dfb0ed05fb38131c">Usage</a></div><div class="ttdeci">static void Usage()</div><div class="ttdef"><b>Definition</b> <a href="AutomaticGainControl__test_8cc_source.html#l00031">AutomaticGainControl_test.cc:31</a></div></div>
<div class="ttc" id="aclassPitchTuner_html"><div class="ttname"><a href="classPitchTuner.html">PitchTuner</a></div><div class="ttdef"><b>Definition</b> <a href="PitchTuner_8cc_source.html#l00085">PitchTuner.cc:86</a></div></div>
</div><!-- fragment --><p>On my system, wxWidgets returns a display PPI of \(96\) rather than the expected value of \(157\) and resizing the frame to \(2000\) pixels or more causes problems.</p>
<p>Here is a screenshot of the GUI with <em>tinwhistleD5.wav</em> and <em>pavucontrol</em> set to record from the "Monitor of Built-in Audio": </p><div class="image">
<img src="GUI.png" alt=""/>
</div>
<p>The original icon is <a href="https://www.flaticon.com/free-icon/tuning-fork_1005015">here</a>. The estimated pitch is shown as \(599.7\) Hz. The large font shows the nearest equal-tempered note and frequency. The pitch error is shown in <em>cents</em>. The interval between two frequencies \(f_{1}\) and \(f_{2}\) is \( 1200\;log_{2}\left(\frac{f_{2}}{f_{1}}\right) \) cents. Thus, a cent is a \(100\)'th of a semi-tone, there are \(1200\) cents in an octave and \(30\) cents corresponds to a frequency ratio of \(1.01747969\). The two indicator circles are green if the pitch error is in the range \(\pm 15\) cents.</p>
<p>Here is a screenshot of the GUI options dialog: </p><div class="image">
<img src="GUI_options.png" alt=""/>
</div>
<h1><a class="anchor" id="example_sec"></a>
Examples of pitch estimation</h1>
<h2><a class="anchor" id="midi_piano_sec"></a>
Equal-tempered C Major scale played on a piano</h2>
<p>The <a href="https://octave.org">Octave</a> script <em>pianof0.m</em> calls <a href="https://abcmidi.sourceforge.io">abc2midi</a> and <a href="https://timidity.sourceforge.net">timidity</a> to generate a <em>wav</em> file containing the equal-tempered C Major scale played on a piano. The <em>abc</em> file is: </p><div class="fragment"><div class="line">X:1 </div>
<div class="line">T:Notes on piano</div>
<div class="line">M:4/4</div>
<div class="line">L:1/4</div>
<div class="line">Q:1/4=120</div>
<div class="line">K:C </div>
<div class="line">C D E F G A B c</div>
</div><!-- fragment --><p>The <code>PitchTracker_test</code> command is: </p><div class="fragment"><div class="line">$ bin/PitchTracker_test --debug --removeDC --sampleRate 48000 \</div>
<div class="line">  --subSample 2 --inputLpFilterCutoff 1000 --baseLineHpFilterCutoff 200 \</div>
<div class="line">  --threshold 0.100000 --msTsample 1 --file piano.wav</div>
</div><!-- fragment --><p>The following figure shows the minimum of the YIN cumulative mean difference function: </p><div class="image">
<img src="pianof0minCDT.png" alt="" width="600cm"/>
</div>
<p>The following figure shows the <code><a class="el" href="PitchTracker__test_8cc.html">PitchTracker_test.cc</a></code> pitch estimates with the YIN algorithm: </p><div class="image">
<img src="pianof0.png" alt="" width="600cm"/>
</div>
<p><em>pianof0.m</em> finds the following average pitch estimates for the <em>timidity</em> piano sound font:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Note   </th><th class="markdownTableHeadRight">Nominal F0   </th><th class="markdownTableHeadRight">Mean F0 estimate   </th><th class="markdownTableHeadRight">Error(%)   </th><th class="markdownTableHeadRight">Error(cents)    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">C4   </td><td class="markdownTableBodyRight">261.63   </td><td class="markdownTableBodyRight">261.77   </td><td class="markdownTableBodyRight">0.05   </td><td class="markdownTableBodyRight">0.95    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">D4   </td><td class="markdownTableBodyRight">293.66   </td><td class="markdownTableBodyRight">293.53   </td><td class="markdownTableBodyRight">-0.05   </td><td class="markdownTableBodyRight">-0.80    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">E4   </td><td class="markdownTableBodyRight">329.63   </td><td class="markdownTableBodyRight">329.71   </td><td class="markdownTableBodyRight">0.02   </td><td class="markdownTableBodyRight">0.41    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">F4   </td><td class="markdownTableBodyRight">349.23   </td><td class="markdownTableBodyRight">349.29   </td><td class="markdownTableBodyRight">0.02   </td><td class="markdownTableBodyRight">0.33    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">G4   </td><td class="markdownTableBodyRight">392.00   </td><td class="markdownTableBodyRight">392.18   </td><td class="markdownTableBodyRight">0.05   </td><td class="markdownTableBodyRight">0.83    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">A4   </td><td class="markdownTableBodyRight">440.00   </td><td class="markdownTableBodyRight">439.98   </td><td class="markdownTableBodyRight">-0.01   </td><td class="markdownTableBodyRight">-0.10    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">B4   </td><td class="markdownTableBodyRight">493.88   </td><td class="markdownTableBodyRight">494.35   </td><td class="markdownTableBodyRight">0.10   </td><td class="markdownTableBodyRight">1.64    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">C5   </td><td class="markdownTableBodyRight">523.25   </td><td class="markdownTableBodyRight">523.77   </td><td class="markdownTableBodyRight">0.10   </td><td class="markdownTableBodyRight">1.70   </td></tr>
</table>
<h2><a class="anchor" id="heed_sec"></a>
"heed"</h2>
<p>The following figure shows the word "heed": </p><div class="image">
<img src="heed.png" alt="" width="600cm"/>
</div>
<p>The <code>PitchTracker_test</code> command is: </p><div class="fragment"><div class="line">$ bin/PitchTracker_test --debug --removeDC --sampleRate 10000 \</div>
<div class="line">  --subSample --msWindow 25 --inputLpFilterCutoff 1000 \</div>
<div class="line">  --baseLineHpFilterCutoff 200 --msTsample 1 --msTmax 10 \</div>
<div class="line">  --threshold 0.100000 --file heed.wav</div>
</div><!-- fragment --><p>The following figure shows the pitch estimates for the word "heed": </p><div class="image">
<img src="heedf0.png" alt="" width="600cm"/>
</div>
<p>The origin of the plot of pitch estimate is shifted in time with respect to the input wave form by the input windowing latency.</p>
<p>The following figure shows the cumulative mean normalised difference function for the word "heed" at \(150\)ms: </p><div class="image">
<img src="heed_cdt_150ms.png" alt="" width="600cm"/>
</div>
<p>The following figure shows the cumulative mean normalised difference function for the word "heed" at \(250\)ms: </p><div class="image">
<img src="heed_cdt_250ms.png" alt="" width="600cm"/>
</div>
<p>The last two figures show why the pitch estimate approximately doubles. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.7
</small></address>
</body>
</html>
